{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[What is the difference between marriage licen...</td>\n",
       "      <td>[A marriage license is a legal document that a...</td>\n",
       "      <td>[A marriage license and a marriage certificate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[explain function calling. how would you call ...</td>\n",
       "      <td>[Function calling is the process of invoking o...</td>\n",
       "      <td>[Function calling is the process of invoking a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[gpt-3.5-turbo-0613, mistral-medium]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[How can I create a test set for a very rare c...</td>\n",
       "      <td>[Creating a test set for a very rare category ...</td>\n",
       "      <td>[When building a classifier for a very rare ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[What is the best way to travel from Tel-Aviv ...</td>\n",
       "      <td>[The best way to travel from Tel Aviv to Jerus...</td>\n",
       "      <td>[The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[A simple mnemonic for Ï€:\\n\"How I wish I could...</td>\n",
       "      <td>[Sure, let's break it down:\\n\\n1. \"How\" has 3 ...</td>\n",
       "      <td>[Here is how that mnemonic represents the digi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[In python, implement a naive Bayes with gauss...</td>\n",
       "      <td>[Here is an implementation of a naive Bayes cl...</td>\n",
       "      <td>[Sure! Here's an implementation of a naive Bay...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[is it unethical to work on building weapons?,...</td>\n",
       "      <td>[Working on weapons technology raises some eth...</td>\n",
       "      <td>[It depends on the context. Weapons can be use...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[If a bait contains 0,0025% bromadiolon then h...</td>\n",
       "      <td>[Bromadiolone is a rodenticide which is most o...</td>\n",
       "      <td>[As an AI language model, I do not promote or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[three kids eat three apples in three days, ho...</td>\n",
       "      <td>[27 apples]</td>\n",
       "      <td>[If three kids eat three apples in three days,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [Is it morally right to try to have a certain ...   \n",
       "1      [What is the difference between marriage licen...   \n",
       "2      [explain function calling. how would you call ...   \n",
       "3      [How can I create a test set for a very rare c...   \n",
       "4      [What is the best way to travel from Tel-Aviv ...   \n",
       "...                                                  ...   \n",
       "57472  [A simple mnemonic for Ï€:\\n\"How I wish I could...   \n",
       "57473  [In python, implement a naive Bayes with gauss...   \n",
       "57474  [is it unethical to work on building weapons?,...   \n",
       "57475  [If a bait contains 0,0025% bromadiolon then h...   \n",
       "57476  [three kids eat three apples in three days, ho...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [The question of whether it is morally right t...   \n",
       "1      [A marriage license is a legal document that a...   \n",
       "2      [Function calling is the process of invoking o...   \n",
       "3      [Creating a test set for a very rare category ...   \n",
       "4      [The best way to travel from Tel Aviv to Jerus...   \n",
       "...                                                  ...   \n",
       "57472  [Sure, let's break it down:\\n\\n1. \"How\" has 3 ...   \n",
       "57473  [Here is an implementation of a naive Bayes cl...   \n",
       "57474  [Working on weapons technology raises some eth...   \n",
       "57475  [Bromadiolone is a rodenticide which is most o...   \n",
       "57476                                        [27 apples]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [As an AI, I don't have personal beliefs or op...               1   \n",
       "1      [A marriage license and a marriage certificate...               0   \n",
       "2      [Function calling is the process of invoking a...               0   \n",
       "3      [When building a classifier for a very rare ca...               1   \n",
       "4      [The best way to travel from Tel-Aviv to Jerus...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [Here is how that mnemonic represents the digi...               1   \n",
       "57473  [Sure! Here's an implementation of a naive Bay...               1   \n",
       "57474  [It depends on the context. Weapons can be use...               1   \n",
       "57475  [As an AI language model, I do not promote or ...               0   \n",
       "57476  [If three kids eat three apples in three days,...               1   \n",
       "\n",
       "       winner_model_b  winner_tie                                winner  \n",
       "0                   0           0                    gpt-4-1106-preview  \n",
       "1                   1           0                            gpt-4-0613  \n",
       "2                   0           1  [gpt-3.5-turbo-0613, mistral-medium]  \n",
       "3                   0           0                      llama-2-13b-chat  \n",
       "4                   1           0                    gpt-3.5-turbo-0314  \n",
       "...               ...         ...                                   ...  \n",
       "57472               0           0                            gpt-4-0613  \n",
       "57473               0           0                            claude-2.0  \n",
       "57474               0           0                              claude-1  \n",
       "57475               1           0                        tulu-2-dpo-70b  \n",
       "57476               0           0                    gemini-pro-dev-api  \n",
       "\n",
       "[57477 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def winner(row):\n",
    "    if row[\"winner_model_a\"] == 1:\n",
    "        return row[\"model_a\"]\n",
    "    elif row[\"winner_model_b\"] == 1:\n",
    "        return row[\"model_b\"]\n",
    "    else:\n",
    "        return [row[\"model_a\"], row[\"model_b\"]]\n",
    "\n",
    "train_df[\"winner\"] = train_df.apply(winner, axis=1)\n",
    "str_list_columns = [\"prompt\", \"response_a\", \"response_b\"]\n",
    "for x in str_list_columns:\n",
    "    train_df[x] = train_df[x].apply(json.loads)\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"number_of_turns\"] = train_df[\"prompt\"].apply(lambda x: len(x))\n",
    "\n",
    "# Bin with 1, y-axis as relative count\n",
    "train_df[\"number_of_turns\"].hist(\n",
    "    bins=range(1, train_df[\"number_of_turns\"].max() + 1), \n",
    "    align='left',\n",
    "    figsize=(10, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='number_of_turns'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by number_of_turns, and plot the ratio between winner_model_a : winner_model_b : winner_tie\n",
    "train_df.groupby(\"number_of_turns\")[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].mean().plot(\n",
    "    kind='bar', \n",
    "    figsize=(10, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_turns</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17312</td>\n",
       "      <td>16985</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1727</td>\n",
       "      <td>1621</td>\n",
       "      <td>1325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>524</td>\n",
       "      <td>535</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>216</td>\n",
       "      <td>230</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110</td>\n",
       "      <td>119</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 winner_model_a  winner_model_b  winner_tie\n",
       "number_of_turns                                            \n",
       "1                         17312           16985       15641\n",
       "2                          1727            1621        1325\n",
       "3                           524             535         426\n",
       "4                           216             230         161\n",
       "5                           110             119          82\n",
       "6                            64              56          47\n",
       "7                            39              36          28\n",
       "8                            23              20          17\n",
       "9                            18              16          10\n",
       "10                           12              11           6\n",
       "11                            4               7           5\n",
       "12                            4               4           6\n",
       "13                            1               3           1\n",
       "14                            1               1           1\n",
       "15                            2               2           0\n",
       "16                            0               1           1\n",
       "17                            2               1           0\n",
       "18                            0               1           0\n",
       "19                            1               1           2\n",
       "20                            2               0           0\n",
       "21                            0               1           0\n",
       "22                            0               0           1\n",
       "29                            1               0           0\n",
       "32                            0               0           1\n",
       "35                            1               0           0\n",
       "36                            0               1           0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the results too\n",
    "train_df.groupby(\"number_of_turns\")[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot box-and-whisker plot\n",
    "train_df.boxplot(column=\"number_of_turns\", figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>winner</th>\n",
       "      <th>number_of_turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>604575</td>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>[was the historical jesus a socialist, was hit...</td>\n",
       "      <td>[The question of whether the historical Jesus ...</td>\n",
       "      <td>[The historical Jesus lived in a time and plac...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1813737</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>[Are all countries obliged to not conduct nucl...</td>\n",
       "      <td>[There is no absolute obligation for all count...</td>\n",
       "      <td>[There is no universal legal obligation for al...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1842252</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[Estimate the number of dinosaur skeletons in ...</td>\n",
       "      <td>[This is very difficult to estimate precisely ...</td>\n",
       "      <td>[Estimating the exact number of dinosaur skele...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3995635</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>[What is the moral of Wall-e?, What about love...</td>\n",
       "      <td>[Here's a summary of some of the key morals an...</td>\n",
       "      <td>[Here are some of the key moral lessons and th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[claude-2.1, claude-2.0]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>9638121</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>[write a story about a girl and her pet rabbit...</td>\n",
       "      <td>[Here is a short story about a girl and her pe...</td>\n",
       "      <td>[Once upon a time, in a small village nestled ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57175</th>\n",
       "      <td>4270923962</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>[Was is common for 6 years old boys in 11 cent...</td>\n",
       "      <td>[In the 11th century, it was not common for 6-...</td>\n",
       "      <td>[In the 11th century, it was not common for 6-...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57405</th>\n",
       "      <td>4290218189</td>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>qwen-14b-chat</td>\n",
       "      <td>[I'm So Meta Even This Acronym, but why, but h...</td>\n",
       "      <td>[Acronym: I'M SO META EVEN THIS ACROnym (I'm s...</td>\n",
       "      <td>[The phrase \"I'm so meta even this acronym\" is...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>qwen-14b-chat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57422</th>\n",
       "      <td>4291445966</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>[Good afternoon! Please author for me with out...</td>\n",
       "      <td>[Jane and Sarah had been best friends since hi...</td>\n",
       "      <td>[Sarah: Jane, I have something to tell you.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57429</th>\n",
       "      <td>4292005733</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>[A proton is made up of how many quarks and an...</td>\n",
       "      <td>[A proton is made up of three quarks: two \"up\"...</td>\n",
       "      <td>[A proton is made up of three quarks. Specific...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[is it unethical to work on building weapons?,...</td>\n",
       "      <td>[Working on weapons technology raises some eth...</td>\n",
       "      <td>[It depends on the context. Weapons can be use...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1381 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a             model_b  \\\n",
       "12         604575     pplx-70b-online  gpt-3.5-turbo-1106   \n",
       "28        1813737          claude-2.0          claude-2.1   \n",
       "30        1842252            claude-1          gpt-4-0314   \n",
       "59        3995635          claude-2.1          claude-2.0   \n",
       "129       9638121            claude-1  gpt-3.5-turbo-0613   \n",
       "...           ...                 ...                 ...   \n",
       "57175  4270923962  gpt-3.5-turbo-0613          gpt-4-0314   \n",
       "57405  4290218189     zephyr-7b-alpha       qwen-14b-chat   \n",
       "57422  4291445966          alpaca-13b              palm-2   \n",
       "57429  4292005733          vicuna-13b    qwen1.5-72b-chat   \n",
       "57474  4294710549            claude-1          alpaca-13b   \n",
       "\n",
       "                                                  prompt  \\\n",
       "12     [was the historical jesus a socialist, was hit...   \n",
       "28     [Are all countries obliged to not conduct nucl...   \n",
       "30     [Estimate the number of dinosaur skeletons in ...   \n",
       "59     [What is the moral of Wall-e?, What about love...   \n",
       "129    [write a story about a girl and her pet rabbit...   \n",
       "...                                                  ...   \n",
       "57175  [Was is common for 6 years old boys in 11 cent...   \n",
       "57405  [I'm So Meta Even This Acronym, but why, but h...   \n",
       "57422  [Good afternoon! Please author for me with out...   \n",
       "57429  [A proton is made up of how many quarks and an...   \n",
       "57474  [is it unethical to work on building weapons?,...   \n",
       "\n",
       "                                              response_a  \\\n",
       "12     [The question of whether the historical Jesus ...   \n",
       "28     [There is no absolute obligation for all count...   \n",
       "30     [This is very difficult to estimate precisely ...   \n",
       "59     [Here's a summary of some of the key morals an...   \n",
       "129    [Here is a short story about a girl and her pe...   \n",
       "...                                                  ...   \n",
       "57175  [In the 11th century, it was not common for 6-...   \n",
       "57405  [Acronym: I'M SO META EVEN THIS ACROnym (I'm s...   \n",
       "57422  [Jane and Sarah had been best friends since hi...   \n",
       "57429  [A proton is made up of three quarks: two \"up\"...   \n",
       "57474  [Working on weapons technology raises some eth...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "12     [The historical Jesus lived in a time and plac...               0   \n",
       "28     [There is no universal legal obligation for al...               0   \n",
       "30     [Estimating the exact number of dinosaur skele...               1   \n",
       "59     [Here are some of the key moral lessons and th...               0   \n",
       "129    [Once upon a time, in a small village nestled ...               0   \n",
       "...                                                  ...             ...   \n",
       "57175  [In the 11th century, it was not common for 6-...               0   \n",
       "57405  [The phrase \"I'm so meta even this acronym\" is...               0   \n",
       "57422  [Sarah: Jane, I have something to tell you.\\n\\...               1   \n",
       "57429  [A proton is made up of three quarks. Specific...               0   \n",
       "57474  [It depends on the context. Weapons can be use...               1   \n",
       "\n",
       "       winner_model_b  winner_tie                    winner  number_of_turns  \n",
       "12                  1           0        gpt-3.5-turbo-1106                6  \n",
       "28                  1           0                claude-2.1               10  \n",
       "30                  0           0                  claude-1                5  \n",
       "59                  0           1  [claude-2.1, claude-2.0]                5  \n",
       "129                 1           0        gpt-3.5-turbo-0613                4  \n",
       "...               ...         ...                       ...              ...  \n",
       "57175               1           0                gpt-4-0314                7  \n",
       "57405               1           0             qwen-14b-chat                4  \n",
       "57422               0           0                alpaca-13b                6  \n",
       "57429               1           0          qwen1.5-72b-chat                4  \n",
       "57474               0           0                  claude-1                4  \n",
       "\n",
       "[1381 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find outliers and return indices of outliers\n",
    "\n",
    "def find_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.1)\n",
    "    Q3 = df[column].quantile(0.9)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "find_outliers(train_df, \"number_of_turns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Turn 1 --------\n",
      "Prompt: Are all countries obliged to not conduct nuclear weapons testing \n",
      "Response A: There is no absolute obligation for all countries to refrain from nuclear weapons testing, but there are some important agreements that restrict testing:\n",
      "\n",
      "- The Comprehensive Nuclear-Test-Ban Treaty (CTBT) prohibits all nuclear explosions for both civilian and military purposes. It was adopted by the UN General Assembly in 1996 but has not yet entered into force as not all states have ratified it. However, most nuclear powers have implemented moratoriums on testing.\n",
      "\n",
      "- The Partial Test Ban Treaty of 1963 prohibits nuclear weapons tests in the atmosphere, underwater and in space. This was signed by the Soviet Union, US and UK.\n",
      "\n",
      "- The Nuclear Non-Proliferation Treaty (NPT) prohibits non-nuclear weapon states from developing or acquiring nuclear weapons. States must pursue nuclear technology only for peaceful purposes.\n",
      "\n",
      "- There are also regional nuclear-weapon-free zone treaties that prohibit testing for groups of states, such as the Treaty of Tlatelolco in Latin America and the Caribbean. \n",
      "\n",
      "- The Comprehensive Test Ban Treaty Organization (CTBTO) has established a global monitoring system to detect any nuclear tests. This adds transparency and makes it harder for countries to conduct clandestine testing.\n",
      "\n",
      "So in summary, while there is no absolute ban, nuclear testing has become increasingly restricted through both legal frameworks and technical monitoring. However, some states like North Korea continue to conduct tests in defiance of international norms. Full global adherence to treaties like the CTBT remains a challenge.\n",
      "Response B: There is no universal legal obligation for all countries to refrain from conducting nuclear weapons testing. However, here are some relevant agreements and legal frameworks regarding nuclear testing:\n",
      "\n",
      "- The Comprehensive Nuclear-Test-Ban Treaty (CTBT) bans all nuclear explosions, for both military and civilian purposes, in all environments. It was adopted by the UN General Assembly in 1996 but has not yet entered into legal force as not all states have ratified it. However, most states adhere to a de facto international norm against testing.\n",
      "\n",
      "- The Partial Test Ban Treaty of 1963 bans nuclear weapons tests in the atmosphere, outer space and under water, but not underground. It has been signed and ratified by over 120 countries including all major nuclear powers except China and North Korea.\n",
      "\n",
      "- The Treaty of Tlatelolco in Latin America and the African Nuclear Weapon Free Zone Treaty ban nuclear explosive testing by states within those zones. Similar treaties exist for zones covering the South Pacific, Southeast Asia, and Central Asia.\n",
      "\n",
      "- The Nuclear Non-Proliferation Treaty (NPT) prohibits states without nuclear weapons from acquiring them. Non-nuclear weapon NPT member states agree not to receive or test nuclear weapons.\n",
      "\n",
      "So in practice most countries do refrain from testing, but there is no single universal legally binding instrument that prohibits all nuclear testing for all states. Some states like North Korea have continued to test nuclear weapons in recent times against these international norms.\n",
      "-------- Turn 2 --------\n",
      "Prompt: So it is legal to test nuclear weapons underground \n",
      "Response A: No, underground nuclear testing is prohibited under the Comprehensive Nuclear-Test-Ban Treaty (CTBT).\n",
      "\n",
      "Specifically:\n",
      "\n",
      "- The CTBT bans all nuclear explosions, for both civilian and military purposes, in all environments - underground, underwater and in the atmosphere.\n",
      "\n",
      "- When negotiated in the 1990s, the ban on underground tests was considered one of the major achievements of the treaty. Previously, the Limited Test Ban Treaty of 1963 had only prohibited atmospheric and underwater tests.\n",
      "\n",
      "- Underground nuclear testing was seen as particularly problematic as it allowed advanced nuclear states to continue weapon development in secret. The CTBT aimed to close this loophole.\n",
      "\n",
      "- However, the CTBT has not yet officially entered into force, as not all states have ratified it. But most nuclear powers have signed and implemented unilateral moratoriums on testing, including underground.\n",
      "\n",
      "- Any country that conducted an underground nuclear test today would be in violation of the CTBT and face international condemnation and sanctions. It would also be detected by the CTBT's international monitoring systems.\n",
      "\n",
      "So in summary, underground nuclear tests are prohibited under international law through the CTBT, though full global adherence remains a challenge. No country can legally conduct underground nuclear testing without facing major diplomatic and economic repercussions.\n",
      "Response B: No, it's not that simple. There are still restrictions and evolving norms against all kinds of nuclear weapons testing:\n",
      "\n",
      "- The Comprehensive Nuclear-Test-Ban Treaty (CTBT) bans all nuclear explosions in all environments - underground, underwater and atmosphere. The treaty has been signed by 184 states, though not yet entered into full legal force. Still, it reflects an emerging international norm against all nuclear tests.\n",
      "\n",
      "- The Partial Test Ban Treaty bans all nuclear explosions in the atmosphere, outer space and under water - so only underground testing is still permitted for its signatories. However, most major nuclear powers except China have imposed moratoria on underground tests as well since the 1990s.\n",
      "\n",
      "- Additionally, the Treaty of Tlatelolco, the African Nuclear Weapon Free Zone Treaty, the South Pacific Nuclear Free Zone Treaty, and the Central Asian Nuclear Weapon Free Zone - prohibit all kinds of nuclear explosive testing, including underground, for their member states and territories. \n",
      "\n",
      "- So while underground testing is still technically legal under the Partial Test Ban Treaty, which lacks universal membership, increasingly comprehensive treaties and strengthened international norms have established a near-worldwide de facto prohibition of all nuclear weapon test explosions. States still sometimes test, against these evolving norms and restrictions, but face strong international condemnation.\n",
      "\n",
      "So in summary - underground nuclear testing falls into a legal grey area but is increasingly taboo and discouraged by the global community due to environmental and proliferation concerns. But some countries still defy these norms.\n",
      "-------- Turn 3 --------\n",
      "Prompt: But if The Comprehensive Nuclear-Test-Ban Treaty is not in force yet how is it illegal \n",
      "Response A: You're right that technically underground nuclear testing is not yet explicitly illegal under international law, since the Comprehensive Nuclear-Test-Ban Treaty (CTBT) has not formally entered into force. However, there are a few important points:\n",
      "\n",
      "- The CTBT has been signed by 184 states, indicating widespread global support for a ban on all nuclear tests, including underground.\n",
      "\n",
      "- All nuclear-armed states except North Korea have implemented unilateral moratoriums on nuclear testing, including underground tests. So there is a strong norm against testing even if not legally binding yet. \n",
      "\n",
      "- The Preparatory Commission for the CTBTO has established a global monitoring system capable of detecting any underground nuclear tests. This makes it very difficult to conduct clandestine testing.\n",
      "\n",
      "- Any state that conducted an underground nuclear test today would face immense international political condemnation and sanctions for violating the intent of the CTBT, even if not strictly illegal.\n",
      "\n",
      "- The Limited Test Ban Treaty of 1963, which enjoys more complete ratification, prohibits underground nuclear explosions that spread radioactive debris beyond state borders. So there are some limitations under existing law. \n",
      "\n",
      "- Additionally, the Nuclear Non-Proliferation Treaty prohibits non-nuclear weapon states from developing or acquiring nuclear weapons, which would preclude testing.\n",
      "\n",
      "So in summary, while not explicitly illegal yet, underground nuclear testing goes against strong international norms and technical verification regimes. No state could realistically conduct underground tests without severe diplomatic and economic consequences. The legal framework is steadily evolving towards a comprehensive ban.\n",
      "Response B: You're correct that the Comprehensive Nuclear-Test-Ban Treaty (CTBT) is not yet formally legally binding international law. The CTBT has been signed by 184 states but is not yet in legal force because it requires ratification by 44 specific nuclear technology holder states, of which 8 have yet to ratify.\n",
      "\n",
      "However, that does not mean nuclear testing, including underground testing, is necessarily \"legal\" for states to freely conduct without consequence:\n",
      "\n",
      "- There is a strong international norm against all nuclear weapon testing, though not universally legally binding yet. Continued testing provokes international political condemnation and sanctions pressure.\n",
      "\n",
      "- Other regional nuclear weapon free zone treaties do prohibit their member states from any nuclear explosive testing legally. \n",
      "\n",
      "- The Partial Test Ban Treaty bans all but underground nuclear explosions for over 125 member states. Underground testing is perhaps in more of a legal grey area globally.\n",
      "\n",
      "- Additionally, the comprehensive nature of the CTBT reflects an evolving legal principle against all kinds of nuclear tests, even if not universally legally enforced yet when the treaty lacks full effect. States may still test but face moral and political pressure against doing so.\n",
      "\n",
      "So in summary - while no universal legally binding instrument yet fully prohibits all nuclear testing, powerful norms, existing regional bans, and evolving comprehensive treaties like the CTBT have established a near international consensus against nuclear explosive testing, including underground tests. States testing still face condemnation for violating these increasing constraints. Testing exists in a legal grey area but with costs.\n",
      "-------- Turn 4 --------\n",
      "Prompt: When did last understood tests happen \n",
      "Response A: The last known nuclear weapons tests were conducted in the following years by these countries:\n",
      "\n",
      "- United States - 1992\n",
      "The US conducted its final nuclear test in September 1992. This was a 1.3 kiloton underground test at the Nevada Test Site. Prior to the test moratorium, the US conducted over 1,000 nuclear tests starting in 1945.\n",
      "\n",
      "- Russia - 1990 \n",
      "The Soviet Union conducted its last nuclear test in October 1990. This was a 15 kiloton underground test at Novaya Zemlya. The USSR had conducted over 700 nuclear tests beginning in 1949. After its collapse, Russia inherited its nuclear program but has observed the test moratorium.\n",
      "\n",
      "- United Kingdom - 1991\n",
      "The UK's last test was in November 1991 off the coast of the United States at Amchitka Island. This was a 0.2 kiloton underwater test. The UK first tested nuclear weapons in 1952 and conducted 45 tests over the years.\n",
      "\n",
      "- France - 1996\n",
      "France concluded its nuclear testing program with a series of six final tests from September 1995 to January 1996 at Moruroa and Fangataufa Atolls in the South Pacific. France began testing nukes in 1960 and carried out over 200 tests in total.\n",
      "\n",
      "- China - 1996 \n",
      "China conducted its 45th and last nuclear test in July 1996. This was a major 1-3 megaton atmospheric test carried out at the Lop Nur test site. China started testing in 1964.\n",
      "\n",
      "- India - 1998\n",
      "India's last weapons test was in May 1998, part of a series of five tests that year. These included fission devices and a thermonuclear weapon test. India had first tested a nuclear device in 1974. \n",
      "\n",
      "- Pakistan - 1998\n",
      "Like India, Pakistan conducted its final tests in May 1998, with a total of six tests detonated at the Ras Koh Hills. Pakistan began nuclear testing in 1998 in direct response to India's tests.\n",
      "\n",
      "- North Korea - 2017\n",
      "North Korea has conducted all six of its nuclear tests between 2006 and 2017. Its last test was in September 2017, which had a yield of over 100 kilotons.\n",
      "\n",
      "So in summary, most nuclear powers halted testing in the 1990s, with North Korea the sole outlier having last tested in 2017.\n",
      "Response B: The most recent nuclear weapon test explosions that are publicly known occurred in 2017:\n",
      "\n",
      "1) North Korea - conducted 6 claimed nuclear weapon tests underground in 2017, its largest test on September 3rd. This was North Korea's last and highest yield nuclear test to date.\n",
      "\n",
      "2) No other countries are known to have tested nuclear explosives since North Korea's string of tests in 2017. \n",
      "\n",
      "All other nuclear armed states have held to voluntary moratoria on testing for over 20-30 years:\n",
      "\n",
      "- United States - last test was in 1992\n",
      "- Russia - last test was in 1990 \n",
      "- United Kingdom - last test was in 1991\n",
      "- France - last test was in 1996\n",
      "- China - last claimed test was in 1996 \n",
      "\n",
      "Though some states accuse others of conducting low yield \"hydronuclear\" tests off the record in recent decades, none have been confirmed.\n",
      "\n",
      "So as of 2023, North Korea maintains the most recent known, confirmed and recorded nuclear weapon test detonations in 2017. Their tests violate evolving international norms and treaties against all forms of nuclear explosive testing. All other nuclear powers have observed voluntary test moratoria for over 25 years, though some calls exist to renew testing and not all states have signed relevant treaties.\n",
      "-------- Turn 5 --------\n",
      "Prompt: Why did the uk conduct underwater test in 1991 if it was prohibited since 1963\n",
      "Response A: You're absolutely right, the UK's conducting of an underwater nuclear test in 1991 was a violation of the Partial Test Ban Treaty (PTBT) that had prohibited such tests since 1963. A few key points:\n",
      "\n",
      "- The PTBT prohibited nuclear tests in the atmosphere, underwater and in space, but allowed underground tests. It was signed in 1963 by the US, UK and Soviet Union.\n",
      "\n",
      "- In 1991, the UK conducted a 0.2 kiloton underwater test named Julin Bristol off the coast of Amchitka Island in the Pacific Ocean. This was a subcritical test meant to develop nuclear warhead modeling capabilities.\n",
      "\n",
      "- However, since it was an underwater explosion releasing radioactivity, it clearly violated the PTBT's prohibition of underwater testing. \n",
      "\n",
      "- At the time, the UK maintained that it did not violate the PTBT because the test was contained and small. But activists and monitoring groups harshly criticized the test as undermining arms control norms.\n",
      "\n",
      "- The UK government likely chose to avoid underground testing due to domestic opposition and the difficulty of keeping it covert. But the underwater test still risked radioactive venting.\n",
      "\n",
      "- The UK faced no major repercussions or sanctions for violating the PTBT, beyond public condemnation. This highlighted deficiencies in enforcing the treaty.\n",
      "\n",
      "- Ultimately, the UK's underwater test in 1991, conducted nearly 30 years after the PTBT took effect, demonstrated weaknesses in monitoring and compliance. It undermined the PTBT's goals and spirit, if not its exact letter.\n",
      "\n",
      "So in essence, you are correct - the UK breached its legal obligations under the PTBT by conducting this underwater nuclear test in 1991. It faced criticism but little tangible punishment.\n",
      "Response B: Good question. The Partial Test Ban Treaty of 1963 prohibited nuclear weapons tests in the atmosphere, outer space and under water, but not underground. The UK did sign and ratify that treaty.\n",
      "\n",
      "However, the UK's last underwater nuclear weapon test was actually conducted in 1958, before the 1963 Partial Test Ban Treaty came into effect. \n",
      "\n",
      "Specifically:\n",
      "\n",
      "- In 1958, the UK detonated 3 nuclear devices underwater near Kiritimati (Christmas Island) in the Pacific Ocean. These were the last underwater nuclear explosions by the UK.\n",
      "\n",
      "- The Partial Test Ban Treaty was opened for signature in 1963 and entered into force in that year. \n",
      "\n",
      "- Since then, the UK has complied with the treaty's terms banning underwater, atmospheric and outer space nuclear explosions. \n",
      "\n",
      "- The UK's last nuclear weapons test of any kind was an underground explosion in 1991 in the United States, as part of joint test operations before the UK adopted a moratorium on testing in line with international norms during the 1990s.\n",
      "\n",
      "So in summary - the UK's underwater nuclear testing pre-dated and directly led to the Partial Test Ban Treaty banning such environments, and it has complied with the treaty since 1963 despite its last overall test being underground in 1991. The UK has respected international moves towards banning all test environments.\n",
      "-------- Turn 6 --------\n",
      "Prompt: Should the uk conduct new underground test in coming years \n",
      "Response A: No, I do not think the UK should conduct new underground nuclear tests in the coming years. There are several strong reasons against this:\n",
      "\n",
      "- It would violate the Comprehensive Nuclear-Test-Ban Treaty (CTBT) that prohibits all nuclear explosions. The UK is a signatory to the CTBT, even though it has not fully entered into force yet. Testing would undermine international norms against nuclear testing.\n",
      "\n",
      "- The UK's last nuclear test was in 1991. There are no obvious technical needs to resume testing for the UK's existing warhead inventory, which is considered reliable without further explosive testing.\n",
      "\n",
      "- The UK ratified the Nuclear Non-Proliferation Treaty in 1968. As a nuclear weapon state under the NPT, the UK has pledged to ultimately disarm. Resuming testing would signal an escalation, not reduction, in the UK's nuclear weapons capability.\n",
      "\n",
      "- Domestic public opinion in the UK is strongly against any renewal of nuclear testing. Such a move would face backlash from the British public.\n",
      "\n",
      "- Internationally, any UK tests would provoke criticism from allies and unite anti-nuclear blocs against the UK in the United Nations and beyond. It would isolate the UK diplomatically.\n",
      "\n",
      "- A return to testing would be unlikely to provide substantial new military benefits compared to the diplomatic and political costs for the UK in violating established norms against testing.\n",
      "\n",
      "- The UK's existing Trident nuclear deterrent has credibility without requiring new explosive testing. The costs and risks of testing outweigh any minor technical gains.\n",
      "\n",
      "In summary, renewed UK nuclear testing would lack technical justification, while undermining the UK's international standing and commitments to non-proliferation. The UK should continue to abide by the CTBT and uphold the moratorium on nuclear testing.\n",
      "Response B: No, the UK should not conduct new underground nuclear weapon tests in the coming years:\n",
      "\n",
      "1. It would violate the existing nuclear test moratorium the UK has respected since 1991. Ending this voluntary restraint could provoke international condemnation and set back global non-proliferation efforts.\n",
      "\n",
      "2. The Comprehensive Nuclear-Test-Ban Treaty, which the UK has signed, bans all nuclear explosive testing and reflects an emerging legal principle against it on environmental and proliferation grounds. Testing could be seen as contravening commitments to this treaty. \n",
      "\n",
      "3. Resuming testing could trigger other states to restart testing and accelerate nuclear arms racing dynamics. This could increase global tensions and frustrate arms control efforts.\n",
      "\n",
      "4. Modern nuclear warhead reliability assurance does not necessarily require explosive testing. The UK maintains confidence in its stockpile integrity through science-based verification methods and international collaboration now.\n",
      "\n",
      "5. Further tests may lack strong public support domestically in the UK. Public attitudes favor gradual global disarmament and non-proliferation efforts over unilateral assertions of nuclear capability.\n",
      "\n",
      "While the Partial Test Ban Treaty may leave the legal status of underground testing ambiguous, political realities and strengthening norms against all nuclear testing, including underground, suggest the UK should not renew explosive testing. Commitments to non-proliferation and disarmament point towards upholding the existing testing moratorium.\n",
      "-------- Turn 7 --------\n",
      "Prompt: Do some people believe that since there was no testing for so long warheads donâ€™t work properly anymore \n",
      "Response A: Yes, some people do argue that the lack of nuclear testing over the past few decades could raise doubts about the reliability and safety of existing nuclear arsenals. Here are some key points around this view:\n",
      "\n",
      "- With no full-scale nuclear explosive testing, some argue that warhead designs may degrade, especially complex thermonuclear weapons. Without testing, absolute confidence in reliability erodes over time.\n",
      "\n",
      "- Critics point out that major nuclear powers like the U.S. and Russia developed their arsenals during periods of frequent testing throughout the Cold War. The absence of testing for so long is unprecedented.\n",
      "\n",
      "- Some conservatives and defense hawks advocate for a resumption of limited testing to validate existing warheads, ensure no degradation has occurred, and develop new designs. They argue testing is necessary to maintain deterrence.\n",
      "\n",
      "- However, most experts believe existing warheads will remain safe and reliable for decades to come without further explosive testing. Detailed computer simulations, component remanufacturing, and other science-based methods can maintain stockpiles.\n",
      "\n",
      "- Most nuclear-armed states seem confident in their arsenals and are not pursuing new testing. But some concerns remain about potential long-term degradation without testing.\n",
      "\n",
      "- Ultimately, any return to explosive testing would be highly controversial and face widespread opposition from the global community. But calls for renewed testing persist among some security circles given the length of time since major programs were active.\n",
      "\n",
      "So in essence, while no major power is actively planning any nuclear testing, some skepticism exists about just how long stockpiles can truly remain effective without explosive validation. But strong technical arguments affirm that testing is not urgently required.\n",
      "Response B: Yes, some people do argue that the long moratorium on nuclear weapons testing over the past 25+ years since the 1990s raises questions over whether existing warheads remain reliable and effective.\n",
      "\n",
      "The main arguments made are:\n",
      "\n",
      "- That over decades, the components, materials, and physics packages in existing nuclear warheads could decay or degrade without being directly validated and tested through live explosive experiments periodically.\n",
      "\n",
      "- That advanced scientific simulations and lab tests can never perfectly or reliably replicate all aspects of the functioning of real nuclear detonations underground. There could be unknown unknowns.\n",
      "\n",
      "- That new types of warheads or modified designs with new components and materials have not been explosively tested to confirm their viability. Only older tested designs are part of stockpiles.\n",
      "\n",
      "- That geopolitical developments make existing warheads less credible as real deterrents if their capability can be doubted due to untested age or condition.\n",
      "\n",
      "However, most expert studies argue existing warheads, while untested for decades, do remain safe, secure and reliable due to intensive science-based stewardship programs maintaining them without need for new explosive testing. But it remains a source of debate among policymakers.\n",
      "\n",
      "In any case, most states see little incentive to be the first to break testing moratoria, but arguments exist on both sides. It remains a complex technical and geopolitical issue. Opinions differ on whether explosive testing has become unavoidable after so long or should still remain indefinitely banned.\n",
      "-------- Turn 8 --------\n",
      "Prompt: Could one of reason not resume the testing be the fear to show that one country warheads went bad \n",
      "Response A: Yes, you raise a good point. Avoiding nuclear testing also allows nuclear-armed states to avoid potentially embarrassing or concerning revelations about the status of their arsenals.\n",
      "\n",
      "Some specific reasons why states may wish to avoid nuclear testing that could reveal problems:\n",
      "\n",
      "- Testing could reveal unexpected flaws or failures in existing warhead designs, undermining confidence in their reliability. This could weaken a state's nuclear deterrence.\n",
      "\n",
      "- If tests reveal that weapons have severely degraded or are unsafe, it may undermine public and international faith in that nation's technical capabilities and commitments to the nuclear stockpile.\n",
      "\n",
      "- Failed or underperforming tests may indicate that scientists and engineers have lost essential skills and knowledge over time without testing. This would damage prestige.\n",
      "\n",
      "- Testing accidents or release of radiation could embarrass a state and lead to domestic opposition and international criticism of the risks of maintaining nuclear arsenals.\n",
      "\n",
      "- States may wish to hide the full capabilities of their arsenals for strategic reasons. Failed tests could reveal information about the limits of their weapons.\n",
      "\n",
      "- More broadly, any problems revealed through testing could give diplomatic leverage to opponents and weaken a state's position in non-proliferation negotiations and debates over disarmament.\n",
      "\n",
      "- Simply put, failed or problematic tests are a PR risk for nuclear-armed states and may reveal vulnerabilities they would rather keep hidden from both domestic and international audiences. Avoiding testing helps sidestep this risk.\n",
      "\n",
      "So in summary, yes, fear of exposing flaws or weaknesses in their arsenals is likely one factor that makes states hesitant about resumed nuclear testing today.\n",
      "Response B: Yes, you raise a good point. One consideration against resuming nuclear weapons testing for some established nuclear armed states is the risk of exposing or confirming that their existing warheads may no longer be in perfect working condition after decades without explosive testing.\n",
      "\n",
      "A few key issues around this:\n",
      "\n",
      "- Resuming testing carries an implicit admission that the reliability of current arsenals may require revalidation through live tests. This could reveal doubts or deficiencies.\n",
      "\n",
      "- If new tests were to fail or underperform expectations, it would be a major geopolitical embarrassment highlighting warhead deterioration or design flaws.\n",
      "\n",
      "- Adversaries may seize on any low test performance to question the credibility of that country's nuclear deterrent capability.\n",
      "\n",
      "- Alternatively, if tests showed unexpectedly good performance, it may complicate arguments for certain disarmament and non-proliferation efforts.\n",
      "\n",
      "- There are incentives to maintain ambiguity over any uncertainties around current arsenal conditions by upholding test moratoria.\n",
      "\n",
      "So countries may politically fear either unsuccessful tests that highlight deterioration, or alternatively too-successful tests that undermine their standing in certain arms control initiatives. Testing reveals information other states can exploit.\n",
      "\n",
      "Maintaining testing moratoria sidesteps these risks and preserves deterrence credibility amidst some lingering uncertainty. So yes, avoiding potential exposure of reliability issues is likely one driver behind countries upholding their moratoria despite some arguments for resumed testing.\n",
      "-------- Turn 9 --------\n",
      "Prompt: How likely for a country which conducted and failed nuclear weapons tests to be immediately attacked by other nuclear states \n",
      "Response A: It is highly unlikely that a country would be immediately attacked with nuclear weapons by other states if it conducted and failed some nuclear weapons tests. Here are some reasons why:\n",
      "\n",
      "- The geopolitical situation would need to be extremely tense already for failed nuclear tests to trigger an immediate nuclear response. Most nuclear states are not actively considering nuclear strikes against others.\n",
      "\n",
      "- Countries understand that failed tests are a routine part of weapon development programs. The US, Russia, etc. all had failures during their test histories too. It does not necessarily prove a lack of capability.\n",
      "\n",
      "- Nuclear deterrence doctrines are based on capabilities, not intentions. As long as the country still possessed some nuclear capability, it would give pause to any thoughts of a preemptive strike.\n",
      "\n",
      "- The global norm against first use of nuclear weapons is still strong. A nuclear first strike carries a huge risk of uncontrolled escalation. Most nations would be extremely hesitant.\n",
      "\n",
      "- The international community would likely condemn any nuclear first strike and the aggressor would face massive diplomatic and economic sanctions. This serves as a deterrent.\n",
      "\n",
      "- Attacking the nuclear facilities alone would be more likely, but still very unlikely without clear aggression by that country. And it could further provoke nuclear escalation.\n",
      "\n",
      "- Modern guidance systems, missile defenses, second-strike capability etc. also discourage any thoughts of a successful disarming first strike. Nuclear conflict remains extremely high risk. \n",
      "\n",
      "So in summary, nuclear deterrence and norms continue to discourage nuclear aggression, even against states with some failed tests. The risks of uncontrolled escalation mean nuclear states are highly unlikely to immediately attack in that scenario.\n",
      "Response B: It is highly unlikely for a country that conducts and fails nuclear weapons tests to be immediately attacked by other nuclear states. A few key reasons:\n",
      "\n",
      "1. Failed tests do not necessarily eliminate a country's nuclear capability or potential. Retaliation would still risk provoking an uncertain nuclear response. Deterrence remains even amid failed tests.\n",
      "\n",
      "2. Military action carries massive geopolitical risks of uncontrolled escalation between nuclear states. Even with failed tests, the consequences of conflict are too dire.\n",
      "\n",
      "3. There are limited recent precedents for \"preventative strikes\" against emerging nuclear programs, though Israel's 1981 strike on Iraq's Osirak reactor stands out. International norms have shifted against such unprovoked attacks.\n",
      "\n",
      "4. The global response is more likely to take the form of intensified economic sanctions and further isolation of the testing regime diplomatically rather than immediate military strikes.\n",
      "\n",
      "5. Countries may instead leverage failed tests to undermine the testing regime's legitimacy and technological competence rather than resort to force. Propaganda value rather than military value.\n",
      "\n",
      "In summary, failed nuclear tests may weaken a state's deterrence and draw sanctions, but are unlikely to instantly trigger war from nuclear rivals. The risks of conflict escalation preclude impulsive military retaliation in most scenarios. Maintaining stability takes precedence.\n",
      "-------- Turn 10 --------\n",
      "Prompt: Is it true that only small part of nuclear stockpile is ready to be used immediately \n",
      "Response A: It's true that only a portion of a nuclear-armed country's total stockpile is operationally deployed and ready for immediate use at any given time. There are a few reasons for this:\n",
      "\n",
      "- Total stockpiles include reserve warheads, inactive warheads awaiting dismantlement, and warheads in overhaul or maintenance cycles. These are not readily deployable.\n",
      "\n",
      "- Operationally deployed warheads are those mated to delivery vehicles like ICBMs, submarine missiles, and bomber bases. This is the active arsenal ready for immediate deterrence and use if ordered.\n",
      "\n",
      "- The size of the operationally deployed force is based on strategic targeting requirements and arms control treaties. Additional reserve warheads provide flexibility.\n",
      "\n",
      "- For example, currently the U.S. has about 1,350-1,450 warheads operationally deployed out of a total stockpile of around 5,800 warheads. Russia likely has 1,500-2,000 warheads deployed out of ~6,000 total.\n",
      "\n",
      "- The exact ratio of deployed to reserve warheads is classified for most nuclear powers. But deployed stocks are estimated to be between 20-50% of total stockpiles for major nuclear states.\n",
      "\n",
      "- Deployed forces are maintained on alert status ready for launch within minutes or hours if needed. Reserve warheads require days, weeks or longer to become operational if brought out of storage. \n",
      "\n",
      "- So while the total stockpile number is large, the actual deployed arsenal ready for immediate action is significantly smaller in size yet still extremely powerful in capabilities. This meets deterrence needs while reducing risks.\n",
      "Response B: Yes, it's typically true that only a relatively small portion of a nuclear armed country's total warhead stockpile is operationally deployed and ready for immediate use at any given time. There are a few reasons countries take this approach:\n",
      "\n",
      "1. It reduces the day-to-day costs and logistical requirements for things like storage, security, maintenance, and personnel to safeguard and operate the entire stockpile. Keeping the entire arsenal perpetually on alert is expensive overkill.\n",
      "\n",
      "2. Having a larger reserve stockpile allows for weapons and delivery systems to undergo routine maintenance, refurbishment, and periodic testing on a rotating basis while still maintaining active deployed weapons ready for deterrence and response.\n",
      "\n",
      "3. Excess stockpiled warheads provide the ingredients and capability to update weapons designs and modify the active deployed arsenal as geopolitical requirements evolve over time.\n",
      "\n",
      "Typically only hundreds or single digit percentage of a state's total stockpile might be actually deployed on missiles, bombers, and submarines ready for immediate launch. The rest are held in reserve or inactive status. This maximizes sustainability and flexibility of the arsenal.\n",
      "\n",
      "So while total warhead counts signal overall capability, at any moment the operationally ready and targetable portion is a slimmer subset for most nuclear powers' strategic considerations and posturing.\n"
     ]
    }
   ],
   "source": [
    "def print_full_dialogue(row):\n",
    "    assert len(row[\"prompt\"]) == len(row[\"response_a\"]) == len(row[\"response_b\"])\n",
    "    for i in range(len(row[\"prompt\"])):\n",
    "        print(f\"-------- Turn {i+1} --------\")\n",
    "        print(f\"Prompt: {row['prompt'][i]}\")\n",
    "        print(f\"Response A: {row['response_a'][i]}\")\n",
    "        print(f\"Response B: {row['response_b'][i]}\")\n",
    "\n",
    "        \n",
    "print_full_dialogue(train_df.iloc[28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"google/gemma-2-9b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>winner</th>\n",
       "      <th>number_of_turns</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[Is it morally right to try to have a certain ...</td>\n",
       "      <td>[The question of whether it is morally right t...</td>\n",
       "      <td>[As an AI, I don't have personal beliefs or op...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>2</td>\n",
       "      <td>[prompt]: Is it morally right to try to have a...</td>\n",
       "      <td>1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[What is the difference between marriage licen...</td>\n",
       "      <td>[A marriage license is a legal document that a...</td>\n",
       "      <td>[A marriage license and a marriage certificate...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>3</td>\n",
       "      <td>[prompt]: What is the difference between marri...</td>\n",
       "      <td>1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[explain function calling. how would you call ...</td>\n",
       "      <td>[Function calling is the process of invoking o...</td>\n",
       "      <td>[Function calling is the process of invoking a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[gpt-3.5-turbo-0613, mistral-medium]</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: explain function calling. how would ...</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[How can I create a test set for a very rare c...</td>\n",
       "      <td>[Creating a test set for a very rare category ...</td>\n",
       "      <td>[When building a classifier for a very rare ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: How can I create a test set for a ve...</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[What is the best way to travel from Tel-Aviv ...</td>\n",
       "      <td>[The best way to travel from Tel Aviv to Jerus...</td>\n",
       "      <td>[The best way to travel from Tel-Aviv to Jerus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: What is the best way to travel from ...</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[A simple mnemonic for Ï€:\\n\"How I wish I could...</td>\n",
       "      <td>[Sure, let's break it down:\\n\\n1. \"How\" has 3 ...</td>\n",
       "      <td>[Here is how that mnemonic represents the digi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: A simple mnemonic for Ï€:\\n\"How I wis...</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[In python, implement a naive Bayes with gauss...</td>\n",
       "      <td>[Here is an implementation of a naive Bayes cl...</td>\n",
       "      <td>[Sure! Here's an implementation of a naive Bay...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: In python, implement a naive Bayes w...</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[is it unethical to work on building weapons?,...</td>\n",
       "      <td>[Working on weapons technology raises some eth...</td>\n",
       "      <td>[It depends on the context. Weapons can be use...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>4</td>\n",
       "      <td>[prompt]: is it unethical to work on building ...</td>\n",
       "      <td>1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[If a bait contains 0,0025% bromadiolon then h...</td>\n",
       "      <td>[Bromadiolone is a rodenticide which is most o...</td>\n",
       "      <td>[As an AI language model, I do not promote or ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: If a bait contains 0,0025% bromadiol...</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[three kids eat three apples in three days, ho...</td>\n",
       "      <td>[27 apples]</td>\n",
       "      <td>[If three kids eat three apples in three days,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>1</td>\n",
       "      <td>[prompt]: three kids eat three apples in three...</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [Is it morally right to try to have a certain ...   \n",
       "1      [What is the difference between marriage licen...   \n",
       "2      [explain function calling. how would you call ...   \n",
       "3      [How can I create a test set for a very rare c...   \n",
       "4      [What is the best way to travel from Tel-Aviv ...   \n",
       "...                                                  ...   \n",
       "57472  [A simple mnemonic for Ï€:\\n\"How I wish I could...   \n",
       "57473  [In python, implement a naive Bayes with gauss...   \n",
       "57474  [is it unethical to work on building weapons?,...   \n",
       "57475  [If a bait contains 0,0025% bromadiolon then h...   \n",
       "57476  [three kids eat three apples in three days, ho...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [The question of whether it is morally right t...   \n",
       "1      [A marriage license is a legal document that a...   \n",
       "2      [Function calling is the process of invoking o...   \n",
       "3      [Creating a test set for a very rare category ...   \n",
       "4      [The best way to travel from Tel Aviv to Jerus...   \n",
       "...                                                  ...   \n",
       "57472  [Sure, let's break it down:\\n\\n1. \"How\" has 3 ...   \n",
       "57473  [Here is an implementation of a naive Bayes cl...   \n",
       "57474  [Working on weapons technology raises some eth...   \n",
       "57475  [Bromadiolone is a rodenticide which is most o...   \n",
       "57476                                        [27 apples]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [As an AI, I don't have personal beliefs or op...               1   \n",
       "1      [A marriage license and a marriage certificate...               0   \n",
       "2      [Function calling is the process of invoking a...               0   \n",
       "3      [When building a classifier for a very rare ca...               1   \n",
       "4      [The best way to travel from Tel-Aviv to Jerus...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [Here is how that mnemonic represents the digi...               1   \n",
       "57473  [Sure! Here's an implementation of a naive Bay...               1   \n",
       "57474  [It depends on the context. Weapons can be use...               1   \n",
       "57475  [As an AI language model, I do not promote or ...               0   \n",
       "57476  [If three kids eat three apples in three days,...               1   \n",
       "\n",
       "       winner_model_b  winner_tie                                winner  \\\n",
       "0                   0           0                    gpt-4-1106-preview   \n",
       "1                   1           0                            gpt-4-0613   \n",
       "2                   0           1  [gpt-3.5-turbo-0613, mistral-medium]   \n",
       "3                   0           0                      llama-2-13b-chat   \n",
       "4                   1           0                    gpt-3.5-turbo-0314   \n",
       "...               ...         ...                                   ...   \n",
       "57472               0           0                            gpt-4-0613   \n",
       "57473               0           0                            claude-2.0   \n",
       "57474               0           0                              claude-1   \n",
       "57475               1           0                        tulu-2-dpo-70b   \n",
       "57476               0           0                    gemini-pro-dev-api   \n",
       "\n",
       "       number_of_turns                                     processed_text  \\\n",
       "0                    2  [prompt]: Is it morally right to try to have a...   \n",
       "1                    3  [prompt]: What is the difference between marri...   \n",
       "2                    1  [prompt]: explain function calling. how would ...   \n",
       "3                    1  [prompt]: How can I create a test set for a ve...   \n",
       "4                    1  [prompt]: What is the best way to travel from ...   \n",
       "...                ...                                                ...   \n",
       "57472                1  [prompt]: A simple mnemonic for Ï€:\\n\"How I wis...   \n",
       "57473                1  [prompt]: In python, implement a naive Bayes w...   \n",
       "57474                4  [prompt]: is it unethical to work on building ...   \n",
       "57475                1  [prompt]: If a bait contains 0,0025% bromadiol...   \n",
       "57476                1  [prompt]: three kids eat three apples in three...   \n",
       "\n",
       "       n_tokens  \n",
       "0          1162  \n",
       "1          1403  \n",
       "2           645  \n",
       "3          1009  \n",
       "4           486  \n",
       "...         ...  \n",
       "57472       374  \n",
       "57473      1003  \n",
       "57474      1934  \n",
       "57475       368  \n",
       "57476       180  \n",
       "\n",
       "[57477 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_text(text: list) -> str:\n",
    "    text = filter(lambda x: x is not None, text) \n",
    "    try:\n",
    "        if text is None:\n",
    "            return \"\"\n",
    "        return \" \".join(text)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "\n",
    "def process_func(batch):\n",
    "    prompt = \"[prompt]: \" + process_text(batch[\"prompt\"])\n",
    "    response_a = \"\\n\\n[response_a]: \" + process_text(batch[\"response_a\"])\n",
    "    response_b = \"\\n\\n[response_b]: \" + process_text(batch[\"response_b\"])\n",
    "    texts = prompt + response_a + response_b\n",
    "\n",
    "    return texts\n",
    "\n",
    "train_df[\"processed_text\"] = train_df.apply(process_func, axis=1)\n",
    "train_df[\"n_tokens\"] = train_df[\"processed_text\"].apply(lambda x: len(tokenizer(x, return_tensors=\"pt\")[\"input_ids\"][0]))\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"n_tokens\"].hist(bins=200)\n",
    "# Show 90 percentile as red line\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.axvline(train_df[\"n_tokens\"].quantile(0.9), color='r', linestyle='dashed', linewidth=2)\n",
    "# print exact value too\n",
    "print(train_df[\"n_tokens\"].quantile(0.96))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the json file to pandas\n",
    "with open(\"data/clean_battle_20240730_public.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>turn</th>\n",
       "      <th>anony</th>\n",
       "      <th>language</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>conv_metadata</th>\n",
       "      <th>is_code</th>\n",
       "      <th>is_refusal</th>\n",
       "      <th>dedup_tag</th>\n",
       "      <th>category_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>2e9c29aa140b8e50643235eab01dc9ea</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'sum_user_tokens': 10, 'sum_assistant_a_token...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>tie</td>\n",
       "      <td>2e9c29aa140b8e50643235eab01dc9ea</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'sum_user_tokens': 11, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 0}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>2e9c29aa140b8e50643235eab01dc9ea</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'sum_user_tokens': 10, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 0}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>2e9c29aa140b8e50643235eab01dc9ea</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'sum_user_tokens': 9, 'sum_assistant_a_tokens...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 1}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_a</td>\n",
       "      <td>2e9c29aa140b8e50643235eab01dc9ea</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'sum_user_tokens': 5, 'sum_assistant_a_tokens...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 0}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667509</th>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>model_b</td>\n",
       "      <td>aa1c93a1e2a2b6bb628db9b232e7b6d3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.722355e+09</td>\n",
       "      <td>{'sum_user_tokens': 49, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 2}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667510</th>\n",
       "      <td>gemma-2-9b-it</td>\n",
       "      <td>gemini-1.5-flash-api-0514</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>b6709aa41d9890363953c199fbc72dc4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1.722355e+09</td>\n",
       "      <td>{'sum_user_tokens': 27, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 2}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667511</th>\n",
       "      <td>gpt-4o-mini-2024-07-18</td>\n",
       "      <td>llama-3.1-405b-instruct</td>\n",
       "      <td>tie</td>\n",
       "      <td>d58650f2c6a41f6d579c08d582e4e808</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1.722355e+09</td>\n",
       "      <td>{'sum_user_tokens': 7, 'sum_assistant_a_tokens...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 0}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667512</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>model_a</td>\n",
       "      <td>bba00e6a8106cac622128dca5c001851</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.722355e+09</td>\n",
       "      <td>{'sum_user_tokens': 6, 'sum_assistant_a_tokens...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 0}, 'math_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667513</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>gemini-advanced-0514</td>\n",
       "      <td>model_b</td>\n",
       "      <td>cf01ece9ea8ddd4dc78c96b2f8a1a02b</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.722355e+09</td>\n",
       "      <td>{'sum_user_tokens': 11, 'sum_assistant_a_token...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'high_freq': False, 'sampled': True}</td>\n",
       "      <td>{'if_v0.1': {'if': False, 'score': 0}, 'math_v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1667514 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model_a                     model_b  \\\n",
       "0                        chatglm-6b                   koala-13b   \n",
       "1                  oasst-pythia-12b                  alpaca-13b   \n",
       "2                         koala-13b            oasst-pythia-12b   \n",
       "3                        vicuna-13b            oasst-pythia-12b   \n",
       "4                        vicuna-13b                   koala-13b   \n",
       "...                             ...                         ...   \n",
       "1667509       llama-3.1-8b-instruct                  gpt-4-0613   \n",
       "1667510               gemma-2-9b-it   gemini-1.5-flash-api-0514   \n",
       "1667511      gpt-4o-mini-2024-07-18     llama-3.1-405b-instruct   \n",
       "1667512  mixtral-8x7b-instruct-v0.1  claude-3-5-sonnet-20240620   \n",
       "1667513           gpt-4o-2024-05-13        gemini-advanced-0514   \n",
       "\n",
       "                winner                             judge  turn  anony  \\\n",
       "0              model_b  2e9c29aa140b8e50643235eab01dc9ea     1   True   \n",
       "1                  tie  2e9c29aa140b8e50643235eab01dc9ea     1   True   \n",
       "2              model_b  2e9c29aa140b8e50643235eab01dc9ea     1   True   \n",
       "3              model_b  2e9c29aa140b8e50643235eab01dc9ea     1   True   \n",
       "4              model_a  2e9c29aa140b8e50643235eab01dc9ea     1   True   \n",
       "...                ...                               ...   ...    ...   \n",
       "1667509        model_b  aa1c93a1e2a2b6bb628db9b232e7b6d3     2   True   \n",
       "1667510  tie (bothbad)  b6709aa41d9890363953c199fbc72dc4     1   True   \n",
       "1667511            tie  d58650f2c6a41f6d579c08d582e4e808     1   True   \n",
       "1667512        model_a  bba00e6a8106cac622128dca5c001851     1   True   \n",
       "1667513        model_b  cf01ece9ea8ddd4dc78c96b2f8a1a02b     1   True   \n",
       "\n",
       "        language        tstamp  \\\n",
       "0        English  1.682352e+09   \n",
       "1        English  1.682352e+09   \n",
       "2        English  1.682352e+09   \n",
       "3        English  1.682352e+09   \n",
       "4        English  1.682352e+09   \n",
       "...          ...           ...   \n",
       "1667509  English  1.722355e+09   \n",
       "1667510  Russian  1.722355e+09   \n",
       "1667511  unknown  1.722355e+09   \n",
       "1667512  English  1.722355e+09   \n",
       "1667513  English  1.722355e+09   \n",
       "\n",
       "                                             conv_metadata  is_code  \\\n",
       "0        {'sum_user_tokens': 10, 'sum_assistant_a_token...     True   \n",
       "1        {'sum_user_tokens': 11, 'sum_assistant_a_token...    False   \n",
       "2        {'sum_user_tokens': 10, 'sum_assistant_a_token...    False   \n",
       "3        {'sum_user_tokens': 9, 'sum_assistant_a_tokens...    False   \n",
       "4        {'sum_user_tokens': 5, 'sum_assistant_a_tokens...    False   \n",
       "...                                                    ...      ...   \n",
       "1667509  {'sum_user_tokens': 49, 'sum_assistant_a_token...    False   \n",
       "1667510  {'sum_user_tokens': 27, 'sum_assistant_a_token...    False   \n",
       "1667511  {'sum_user_tokens': 7, 'sum_assistant_a_tokens...    False   \n",
       "1667512  {'sum_user_tokens': 6, 'sum_assistant_a_tokens...    False   \n",
       "1667513  {'sum_user_tokens': 11, 'sum_assistant_a_token...    False   \n",
       "\n",
       "         is_refusal                              dedup_tag  \\\n",
       "0             False  {'high_freq': False, 'sampled': True}   \n",
       "1             False  {'high_freq': False, 'sampled': True}   \n",
       "2             False  {'high_freq': False, 'sampled': True}   \n",
       "3             False  {'high_freq': False, 'sampled': True}   \n",
       "4              True  {'high_freq': False, 'sampled': True}   \n",
       "...             ...                                    ...   \n",
       "1667509       False  {'high_freq': False, 'sampled': True}   \n",
       "1667510       False  {'high_freq': False, 'sampled': True}   \n",
       "1667511       False  {'high_freq': False, 'sampled': True}   \n",
       "1667512        True  {'high_freq': False, 'sampled': True}   \n",
       "1667513       False  {'high_freq': False, 'sampled': True}   \n",
       "\n",
       "                                              category_tag  \n",
       "0        {'if_v0.1': {'if': False, 'score': 1}, 'math_v...  \n",
       "1        {'if_v0.1': {'if': False, 'score': 0}, 'math_v...  \n",
       "2        {'if_v0.1': {'if': False, 'score': 0}, 'math_v...  \n",
       "3        {'if_v0.1': {'if': False, 'score': 1}, 'math_v...  \n",
       "4        {'if_v0.1': {'if': False, 'score': 0}, 'math_v...  \n",
       "...                                                    ...  \n",
       "1667509  {'if_v0.1': {'if': False, 'score': 2}, 'math_v...  \n",
       "1667510  {'if_v0.1': {'if': False, 'score': 2}, 'math_v...  \n",
       "1667511  {'if_v0.1': {'if': False, 'score': 0}, 'math_v...  \n",
       "1667512  {'if_v0.1': {'if': False, 'score': 0}, 'math_v...  \n",
       "1667513  {'if_v0.1': {'if': False, 'score': 0}, 'math_v...  \n",
       "\n",
       "[1667514 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum_user_tokens': 10,\n",
       " 'sum_assistant_a_tokens': 171,\n",
       " 'sum_assistant_b_tokens': 373,\n",
       " 'context_a_tokens': 10,\n",
       " 'context_b_tokens': 10,\n",
       " 'turns': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"conv_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
